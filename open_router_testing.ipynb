{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d3d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Set model name and load the API key\n",
    "MODEL_NAME0 = 'google/gemma-3-27b-it:free'\n",
    "MODEL_NAME1 = 'deepseek/deepseek-chat-v3-0324:free'\n",
    "API_KEY = getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the LLM\n",
    "agent_1_llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    model=MODEL_NAME0,\n",
    ")\n",
    "\n",
    "agent_2_llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    model=MODEL_NAME1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Gemma, an open-weights AI assistant. I'm a large language model trained by Google DeepMind. The Gemma team are my creators. \n",
      "\n",
      "I am widely available to the public â€“ I'm an *open weights* model, which means I'm pretty accessible! You can find more information about me here: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = agent_1_llm.invoke(\"What model are you?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfd4410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irutI am **DeepSeek-V3**, an advanced AI language model developed by **DeepSeek**. My knowledge is up to date until **July 2024**, and I can assist with a wide range of topics, including general knowledge, coding, writing, and more.  \n",
      "\n",
      "I support **128K context length**, which means I can handle long conversations and large documents effectively. Additionally, I can process **file uploads** (PDFs, Word, Excel, etc.) to extract and analyze text-based information.  \n",
      "\n",
      "Would you like to test my capabilities with a specific question or task? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "response = agent_2_llm.invoke(\"What model are you?\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
