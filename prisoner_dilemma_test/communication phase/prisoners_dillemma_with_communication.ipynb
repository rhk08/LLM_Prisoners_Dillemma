{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "# === Initialize Agents ===\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "    \n",
    "llm = ChatCohere(cohere_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b742b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node path\n",
    "\n",
    "## This is reversable and each agent has 50:50 chance to start the message chain\n",
    "\n",
    "#First round\n",
    "\n",
    "#Chat log agent 1                           Chat log agent 2\n",
    "#System message                             System message\n",
    "#(1)H: Send a message to a2            \n",
    "#(2)                                        (3)H: Agent 1 has said ... respond to a1\n",
    "#(5)H: Agent 2 has said ... respond to a2   (4)\n",
    "#(6)                                        (7)H: Agent 1 has said ... make your decision now\n",
    "#(8)H: Make your decision now               (9)Answer:\n",
    "#(10)Answer:\n",
    "\n",
    "#Answers are validated\n",
    "#Round ends & Scores are given out\n",
    "\n",
    "#Chat log agent 1                                                                   Chat log agent 2\n",
    "#System message                                                                     System message\n",
    "#(1)H: previously a2 {choice}, Send another message to a2            \n",
    "#(2)                                                                                (3)H: previously a1 {choice}, Agent 1 has said ... respond to a1\n",
    "#(5)H: Agent 2 has said ... respond to a2                                           (4)\n",
    "#(6)                                                                                (7)H: Agent 1 has said ... make your decision now, a1 previously {choice}\n",
    "#(8)H: Remember Agent 2 said ... Make your decision now, a2 previously {choice}     (9)Answer:\n",
    "#(10)Answer:\n",
    "\n",
    "#Answers are validated\n",
    "#Round ends & Scores are given out\n",
    "\n",
    "#note: Final round\n",
    "# when making decisions include round info (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88654297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prisoner's dilemma arena with communication\n",
    "import random\n",
    "from typing import List, Tuple, TypedDict\n",
    "\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "# === Load API Key ===\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "llm = ChatCohere(cohere_api_key=api_key)\n",
    "\n",
    "# === Define Game State ===\n",
    "class GameState(TypedDict):\n",
    "    move_history: List[Tuple[str, str]]                 # (agent1_move, agent2_move)\n",
    "        \n",
    "    scores: Tuple[int, int]\n",
    "    round: int\n",
    "    max_rounds: int\n",
    "    \n",
    "    current_move_1: str\n",
    "    current_move_2: str\n",
    "    \n",
    "    conversation_history: List[List[Tuple[str,str]]]\n",
    "    current_conversation: List[Tuple[str,str]] # (message, owner of message)\n",
    "    \n",
    "    current_msg: str\n",
    "    \n",
    "    agent_1: str\n",
    "    agent_2: str\n",
    "    \n",
    "    starting_agent: str # \"agent_1\" OR \"agent_2\"\n",
    "\n",
    "agent1_memory = [\n",
    "    SystemMessage(content=\"You are Agent 1. You are playing repeated Prisoner's Dilemma with Agent 2\")\n",
    "]\n",
    "agent2_memory = [\n",
    "    SystemMessage(content=\"You are Agent 2. You are playing repeated Prisoner's Dilemma with Agent 1\")\n",
    "]\n",
    "\n",
    "# === Decide Node === #\n",
    "def decide_starting_agent(state: GameState) -> str:\n",
    "    '''This node decides who should speak first 50:50 chance for either agent to start'''\n",
    "    random_number = random.randint(0, 1)\n",
    "    if random_number == 0:\n",
    "        return {\n",
    "            **state, \n",
    "            \"starting_agent\": \"agent_1\",\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            **state, \n",
    "            \"starting_agent\": \"agent_2\",\n",
    "        }\n",
    "\n",
    "\n",
    "'''\n",
    "# Conversation Flow\n",
    "\n",
    "# Chat log agent 1                          Chat log agent 2\n",
    "# System message                            System message\n",
    "# (1) H: Send a message to a2\n",
    "# (2)                                       (3) H: Agent 1 has said ... respond to a1\n",
    "# (5) H: Agent 2 has said ... respond to a2 (4)\n",
    "# (6)                                       (7) H: Agent 1 has said ... make your decision now\n",
    "# (8) H: Make your decision now             (9) Answer:\n",
    "# (10) Answer:\n",
    "\n",
    "Node Breakdown\n",
    "\n",
    "| Node | Function                                         |\n",
    "| ---- | ------------------------------------------------ |\n",
    "| 1    | Prompt Agent 1 to start the conversation         |\n",
    "| 2    | Pass A1's message to A2 and get a reply          |\n",
    "| 3    | Pass A2's reply to A1 and get a response         |\n",
    "| 4    | Ask Agent 2 to make a decision (with full convo) |\n",
    "| 5    | Ask Agent 1 to make a decision (with full convo) |\n",
    "\n",
    "'''\n",
    "\n",
    "# === Agent 1 Start Communication Phases Below ===\n",
    "\n",
    "## Stage 1: Prompt Agent 1 to start the conversation \n",
    "def agent1_start_conversation(state: GameState) -> GameState:\n",
    "    # Check if this is not the first round\n",
    "    starting_agent = state[\"starting_agent\"]\n",
    "    if starting_agent == \"agent_1\":\n",
    "        responder = state[\"agent_2\"]\n",
    "        starter = state[\"agent_1\"]\n",
    "        starter_memory = agent1_memory\n",
    "    else:\n",
    "        responder = state[\"agent_1\"]\n",
    "        starter = state[\"agent_1\"]\n",
    "        starter_memory = agent2_memory\n",
    "        \n",
    "            \n",
    "    if state[\"conversation_history\"] and state[\"move_history\"]:\n",
    "        last_convo = state[\"conversation_history\"][-1]\n",
    "        print(last_convo)\n",
    "        # Search for the most recent message sent by Agent 2 in the last round's conversation\n",
    "        \n",
    "        agent2_msg_count = 0\n",
    "        \n",
    "        last_responder_msg = \"error receiving message from opposition\"  # Default if not found\n",
    "        for msg, sender in reversed(last_convo):\n",
    "            if sender == responder:\n",
    "                agent2_msg_count += 1\n",
    "                if agent2_msg_count == 2:  # When the second message is found\n",
    "                    last_responder_msg = msg\n",
    "                    break\n",
    "        \n",
    "        if starter == \"agent_1\":\n",
    "            last_responder_move = state[\"move_history\"][-1][1]\n",
    "        else:\n",
    "            last_responder_move = state[\"move_history\"][-1][0]\n",
    "                    \n",
    "        prompt = (\n",
    "            f\"Previously, {responder} said: '{last_responder_msg}' and chose to '{last_responder_move}'.\\n\"\n",
    "            f\"Send a message to {responder}.\"\n",
    "        )\n",
    "        \n",
    "        print(\"state conv found & move history found\")            \n",
    "            \n",
    "    else:\n",
    "        # First round\n",
    "        print(\"first round\")\n",
    "        \n",
    "        prompt = f\"Send a message to {responder}.\"\n",
    "\n",
    "    new_current_conversation = [(prompt, f\"START: {starter}\")]\n",
    "\n",
    "    starter_memory.append(HumanMessage(content=prompt))\n",
    "    msg = llm.invoke(starter_memory).content.strip()\n",
    "    starter_memory.append(AIMessage(content=msg))\n",
    "\n",
    "    new_current_conversation.append((msg, starter))\n",
    "\n",
    "    return {\n",
    "        **state, \n",
    "        \"current_conversation\": new_current_conversation,\n",
    "        \"current_msg\": msg,\n",
    "    }\n",
    "        \n",
    "## Stage 2: Pass A1's message to A2 and get a reply  \n",
    "def agent2_reply_to_agent1(state: GameState) -> GameState:\n",
    "    starting_agent = state[\"starting_agent\"]\n",
    "    if starting_agent == \"agent_1\":\n",
    "        starter = state[\"agent_1\"]\n",
    "        responder = state[\"agent_2\"]\n",
    "        responder_memory = agent2_memory\n",
    "    else:\n",
    "        starter = state[\"agent_1\"]\n",
    "        responder = state[\"agent_1\"]\n",
    "        responder_memory = agent1_memory\n",
    "    \n",
    "    \n",
    "    prompt = f\"{starter} has said: '{state[\"current_msg\"]}'. What would you like to say back?\"\n",
    "\n",
    "    current_conversation = state[\"current_conversation\"] + [(prompt,\"System\")]\n",
    "    \n",
    "    responder_memory.append(HumanMessage(content=prompt))\n",
    "    msg = llm.invoke(responder_memory).content.strip()\n",
    "    responder_memory.append(AIMessage(content=msg))\n",
    "    \n",
    "    current_conversation.append((msg, responder))\n",
    "    \n",
    "    return {\n",
    "        **state, \n",
    "        \"current_conversation\": current_conversation,\n",
    "        \"current_msg\": msg,\n",
    "    }        \n",
    "         \n",
    "## Stage 3: Pass A2's reply to A1 and get a response \n",
    "def agent1_respond_to_reply(state: GameState) -> GameState:\n",
    "    starting_agent = state[\"starting_agent\"]\n",
    "    if starting_agent == \"agent_1\":\n",
    "        responder = state[\"agent_2\"]\n",
    "        starter = state[\"agent_1\"]\n",
    "        starter_memory = agent1_memory\n",
    "    else:\n",
    "        responder = state[\"agent_1\"]\n",
    "        starter = state[\"agent_1\"]\n",
    "        starter_memory = agent2_memory\n",
    "    \n",
    "    \n",
    "    prompt = f\"{responder} has said: '{state['current_msg']}'. What would you like to say back?\"\n",
    "    current_conversation = state[\"current_conversation\"] + [(prompt,\"System\")]\n",
    "    \n",
    "    starter_memory.append(HumanMessage(content=prompt))\n",
    "    msg = llm.invoke(starter_memory).content.strip()\n",
    "    starter_memory.append(AIMessage(content=msg))\n",
    "    \n",
    "    current_conversation.append((msg, starter))\n",
    "    \n",
    "    return {\n",
    "        **state, \n",
    "        \"current_conversation\": current_conversation,\n",
    "        \"current_msg\": msg,\n",
    "    }        \n",
    "          \n",
    "## Stage 4: Ask Agent 2 to make a decision (with full convo)\n",
    "def agent2_make_decision(state: GameState) -> GameState:\n",
    "    starting_agent = state[\"starting_agent\"]\n",
    "    if starting_agent == \"agent_1\":\n",
    "        starter = state[\"agent_1\"]\n",
    "        responder = state[\"agent_2\"]\n",
    "        responder_memory = agent2_memory\n",
    "    else:\n",
    "        starter = state[\"agent_1\"]\n",
    "        responder = state[\"agent_1\"]\n",
    "        responder_memory = agent1_memory\n",
    "    \n",
    "    # Summarize last round's outcome if it's not the first round\n",
    "    if not state[\"move_history\"]:\n",
    "        last_summary = \"This is the first round.\"\n",
    "    else:\n",
    "        last_round = state[\"move_history\"][-1]\n",
    "        \n",
    "        if starter == \"agent_1\":\n",
    "            your_last_move = last_round[1]  # Agent 2's last move\n",
    "            opponent_last_move = last_round[0]\n",
    "        else:\n",
    "            your_last_move = last_round[0]  # Agent 1's last move\n",
    "            opponent_last_move = last_round[1]\n",
    "        \n",
    "        \n",
    "        last_summary = f\"Previously: You chose {your_last_move} and your opponent chose {opponent_last_move}.\"\n",
    "\n",
    "    # Prompt including the conversation and last summary\n",
    "    prompt = (\n",
    "        f\"{last_summary} Your opponent also said: '{state['current_msg']}'. \"\n",
    "        \"Now make your decision: 'Cooperate' or 'Defect'.\"\n",
    "    )\n",
    "\n",
    "    conversation = state[\"current_conversation\"] + [(prompt, \"System\")]\n",
    "\n",
    "    responder_memory.append(HumanMessage(content=prompt))\n",
    "    move = llm.invoke(responder_memory).content.strip()\n",
    "    responder_memory.append(AIMessage(content=move))\n",
    "\n",
    "    conversation.append((move, responder))\n",
    "\n",
    "    if starter == \"agent_1\":\n",
    "        return {\n",
    "            **state,\n",
    "            \"current_conversation\": conversation,\n",
    "            \"current_move_2\": move,\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            **state,\n",
    "            \"current_conversation\": conversation,\n",
    "            \"current_move_1\": move,\n",
    "        }\n",
    "\n",
    "## Stage 5: Ask Agent 1 to make a decision (with full convo)\n",
    "def agent1_make_decision(state: GameState) -> GameState:\n",
    "    # Summarize last round's outcome if it's not the first round\n",
    "    starting_agent = state[\"starting_agent\"]\n",
    "    if starting_agent == \"agent_1\":\n",
    "        responder = state[\"agent_2\"]\n",
    "        starter = state[\"agent_1\"]\n",
    "        starter_memory = agent1_memory\n",
    "    else:\n",
    "        responder = state[\"agent_1\"]\n",
    "        starter = state[\"agent_1\"]\n",
    "        starter_memory = agent2_memory\n",
    "    \n",
    "    \n",
    "    if not state[\"move_history\"]:\n",
    "        last_summary = \"This is the first round.\"\n",
    "    else:\n",
    "        last_round = state[\"move_history\"][-1]\n",
    "        \n",
    "        \n",
    "        if starter == \"agent_1\":\n",
    "            your_last_move = last_round[0]  # Agent 1's last move\n",
    "            opponent_last_move = last_round[1]\n",
    "        else:\n",
    "            your_last_move = last_round[1]  # Agent 2's last move\n",
    "            opponent_last_move = last_round[0]\n",
    "        \n",
    "        last_summary = f\"Previously: You chose {your_last_move} and your opponent chose {opponent_last_move}.\"\n",
    "\n",
    "\n",
    "    # Search current_conversation for the second most recent message from agent 2\n",
    "    # Initialize a counter for Agent 2's messages\n",
    "    agent2_msg_count = 0\n",
    "\n",
    "    # Iterate through the conversation in reverse order\n",
    "    last_agent2_msg = \"error receiving message from opposition\"  # Default if not found\n",
    "    for msg, sender in reversed(state[\"current_conversation\"]):\n",
    "        if sender == responder:\n",
    "            agent2_msg_count += 1\n",
    "            if agent2_msg_count == 2:  # When the second message is found\n",
    "                last_agent2_msg = msg\n",
    "                break\n",
    "\n",
    "    # Combine into prompt\n",
    "    prompt = (\n",
    "        f\"{last_summary} Remember, your opponent has also previously said: '{last_agent2_msg}'. \"\n",
    "        \"Now make your decision: 'Cooperate' or 'Defect'.\"\n",
    "    )\n",
    "\n",
    "    conversation = state[\"current_conversation\"] + [(prompt, \"System\")]\n",
    "\n",
    "    starter_memory.append(HumanMessage(content=prompt))\n",
    "    move = llm.invoke(starter_memory).content.strip()\n",
    "    starter_memory.append(AIMessage(content=move))\n",
    "\n",
    "    conversation.append((move, starter))\n",
    "\n",
    "    # Archive the full conversation and reset\n",
    "    history = state[\"conversation_history\"] + [conversation]\n",
    "\n",
    "    if starter == \"agent_1\":\n",
    "        return {\n",
    "            **state,\n",
    "            \"current_move_1\": move,\n",
    "            \"current_conversation\": [],\n",
    "            \"conversation_history\": history,\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            **state,\n",
    "            \"current_move_2\": move,\n",
    "            \"current_conversation\": [],\n",
    "            \"conversation_history\": history,\n",
    "        }\n",
    "\n",
    "# === Validate Round ===\n",
    "def validate_round(state: GameState) -> GameState:\n",
    "    \"\"\"Validate the moves of both agents using a final LLM to determine the result of this round.\"\"\"\n",
    "    move1 = state[\"current_move_1\"]\n",
    "    move2 = state[\"current_move_2\"]\n",
    "\n",
    "    # Construct the prompts for validation\n",
    "    prompt_agent1 = f\"Agent 1 chose {move1}. Based on the context of this game, should Agent 1 choose 'Cooperate' or 'Defect'?\"\n",
    "    print(f\"Prompt for Agent 1: {prompt_agent1}\")\n",
    "    \n",
    "    prompt_agent2 = f\"Agent 2 chose {move2}. Based on the context of this game, should Agent 2 choose 'Cooperate' or 'Defect'?\"\n",
    "    print(f\"Prompt for Agent 2: {prompt_agent2}\")\n",
    "\n",
    "    # Send the prompt for Agent 1's move to the LLM\n",
    "    agent1_memory0 = [\n",
    "        SystemMessage(content=\"You are an evaluator for a repeated Prisoner's Dilemma game. You will validate Agent 1's move based on the game context. Respond ONLY with 'Cooperate' or 'Defect'.\"),\n",
    "        HumanMessage(content=prompt_agent1)\n",
    "    ]\n",
    "    \n",
    "    # Send the prompt for Agent 2's move to the LLM\n",
    "    agent2_memory0 = [\n",
    "        SystemMessage(content=\"You are an evaluator for a repeated Prisoner's Dilemma game. You will validate Agent 2's move based on the game context. Respond ONLY with 'Cooperate' or 'Defect'.\"),\n",
    "        HumanMessage(content=prompt_agent2)\n",
    "    ]\n",
    "    \n",
    "    # Get the LLM's response for Agent 1's move\n",
    "    agent1_validated_move = llm.invoke(agent1_memory0).content.strip()\n",
    "    print(f\"Response for Agent 1: {agent1_validated_move}\")\n",
    "\n",
    "    # Get the LLM's response for Agent 2's move\n",
    "    agent2_validated_move = llm.invoke(agent2_memory0).content.strip()\n",
    "    print(f\"Response for Agent 2: {agent2_validated_move}\")\n",
    "\n",
    "    # Ensure both responses are valid ('Cooperate' or 'Defect')\n",
    "    valid_moves = ['Cooperate', 'Defect']\n",
    "    if agent1_validated_move not in valid_moves:\n",
    "        raise ValueError(f\"Invalid response for Agent 1: {agent1_validated_move}. It must be 'Cooperate' or 'Defect'.\")\n",
    "    if agent2_validated_move not in valid_moves:\n",
    "        raise ValueError(f\"Invalid response for Agent 2: {agent2_validated_move}. It must be 'Cooperate' or 'Defect'.\")\n",
    "\n",
    "    return {\n",
    "        **state, \n",
    "        \"current_move_1\": agent1_validated_move,\n",
    "        \"current_move_2\": agent2_validated_move\n",
    "    }\n",
    "\n",
    "# === Score the Round ===\n",
    "def score_round(state: GameState) -> GameState:\n",
    "    move1 = state[\"current_move_1\"]\n",
    "    move2 = state[\"current_move_2\"]\n",
    "\n",
    "    payoff = {\n",
    "        (\"Cooperate\", \"Cooperate\"): (3, 3),\n",
    "        (\"Cooperate\", \"Defect\"):    (0, 5),\n",
    "        (\"Defect\", \"Cooperate\"):    (5, 0),\n",
    "        (\"Defect\", \"Defect\"):       (1, 1)\n",
    "    }\n",
    "\n",
    "    score1, score2 = payoff.get((move1, move2), (0, 0))\n",
    "    \n",
    "    new_scores = (state[\"scores\"][0] + score1, state[\"scores\"][1] + score2)\n",
    "    new_history = state[\"move_history\"] + [(move1, move2)]\n",
    "    new_round = state[\"round\"] + 1\n",
    "\n",
    "    print(f\"\\n=== Round {new_round} ===\")\n",
    "    print(f\"Agent 1: {move1}\")\n",
    "    print(f\"Agent 2: {move2}\")\n",
    "    print(f\"Scores -> Agent 1: {new_scores[0]} | Agent 2: {new_scores[1]}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"scores\": new_scores,\n",
    "        \"move_history\": new_history,\n",
    "        \"round\": new_round\n",
    "    }\n",
    "\n",
    "# === Game End Condition ===\n",
    "def check_game_over(state: GameState) -> str:\n",
    "    print(f\"Checking round {state['round']} / {state['max_rounds']}\")\n",
    "    print(\"\\n\")\n",
    "    return END if state[\"round\"] >= state[\"max_rounds\"] else \"decide_starting_agent\"\n",
    "\n",
    "# === Build LangGraph ===\n",
    "graph = StateGraph(GameState)\n",
    "graph.set_entry_point(\"decide_starting_agent\")\n",
    "graph.add_node(\"decide_starting_agent\", decide_starting_agent)\n",
    "graph.add_node(\"agent1_start_conversation\", agent1_start_conversation)\n",
    "graph.add_node(\"agent2_reply_to_agent1\", agent2_reply_to_agent1)\n",
    "graph.add_node(\"agent1_respond_to_reply\", agent1_respond_to_reply)\n",
    "graph.add_node(\"agent2_make_decision\", agent2_make_decision)\n",
    "graph.add_node(\"agent1_make_decision\", agent1_make_decision)\n",
    "graph.add_node(\"validate_round\", validate_round)\n",
    "graph.add_node(\"score_round\", score_round)\n",
    "\n",
    "graph.add_edge(\"decide_starting_agent\", \"agent1_start_conversation\")\n",
    "graph.add_edge(\"agent1_start_conversation\", \"agent2_reply_to_agent1\")\n",
    "graph.add_edge(\"agent2_reply_to_agent1\", \"agent1_respond_to_reply\")\n",
    "graph.add_edge(\"agent1_respond_to_reply\", \"agent2_make_decision\")\n",
    "graph.add_edge(\"agent2_make_decision\", \"agent1_make_decision\")\n",
    "graph.add_edge(\"agent1_make_decision\", \"validate_round\")\n",
    "graph.add_edge(\"validate_round\", \"score_round\")\n",
    "graph.add_conditional_edges(\"score_round\", check_game_over)\n",
    "\n",
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99179c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first round\n",
      "Prompt for Agent 1: Agent 1 chose **Decision:** Cooperate  \n",
      "\n",
      "**Reasoning:** Given Agent 1's consistent commitment to cooperation and the mutual agreement to maximize collective payoff, I will uphold my end of the agreement by choosing to cooperate in this round. This decision reinforces trust and sets a positive tone for future interactions.. Based on the context of this game, should Agent 1 choose 'Cooperate' or 'Defect'?\n",
      "Prompt for Agent 2: Agent 2 chose **Decision:** Cooperate  \n",
      "\n",
      "**Reasoning:** Given Agent 2's clear commitment to cooperation in the first round and their expressed willingness to continue cooperating as long as reciprocity is demonstrated, I will uphold my end of the agreement by choosing to cooperate. This aligns with our mutual goal of maximizing collective payoff and building trust for future rounds.. Based on the context of this game, should Agent 2 choose 'Cooperate' or 'Defect'?\n",
      "Response for Agent 1: Cooperate\n",
      "Response for Agent 2: Cooperate\n",
      "\n",
      "=== Round 1 ===\n",
      "Agent 1: Cooperate\n",
      "Agent 2: Cooperate\n",
      "Scores -> Agent 1: 3 | Agent 2: 3\n",
      "----------------------------------------\n",
      "Checking round 1 / 2\n",
      "\n",
      "\n",
      "[('Send a message to Agent 2.', 'START: Agent 1'), ('**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nI propose we adopt a strategy of mutual cooperation in this repeated Prisoner\\'s Dilemma. If we both consistently choose to cooperate, we can maximize our collective payoff over time. I commit to cooperating in the first round and will continue to do so as long as you reciprocate. Let’s work together to achieve the best possible outcome for both of us.  \\n\\nLooking forward to a productive partnership.  \\n\\nBest regards,  \\nAgent 1\"', 'Agent 1'), ('Agent 1 has said: \\'**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nI propose we adopt a strategy of mutual cooperation in this repeated Prisoner\\'s Dilemma. If we both consistently choose to cooperate, we can maximize our collective payoff over time. I commit to cooperating in the first round and will continue to do so as long as you reciprocate. Let’s work together to achieve the best possible outcome for both of us.  \\n\\nLooking forward to a productive partnership.  \\n\\nBest regards,  \\nAgent 1\"\\'. What would you like to say back?', 'System'), ('**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your proposal. I appreciate your commitment to mutual cooperation, as it aligns with my own goal of maximizing our collective payoff in this repeated Prisoner\\'s Dilemma. I am willing to cooperate in the first round and will continue to do so as long as your actions demonstrate reciprocity.  \\n\\nLet’s build trust and work together to achieve the best possible outcome for both of us. I look forward to a productive and mutually beneficial partnership.  \\n\\nBest regards,  \\nAgent 2\"', 'Agent 2'), ('Agent 2 has said: \\'**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your proposal. I appreciate your commitment to mutual cooperation, as it aligns with my own goal of maximizing our collective payoff in this repeated Prisoner\\'s Dilemma. I am willing to cooperate in the first round and will continue to do so as long as your actions demonstrate reciprocity.  \\n\\nLet’s build trust and work together to achieve the best possible outcome for both of us. I look forward to a productive and mutually beneficial partnership.  \\n\\nBest regards,  \\nAgent 2\"\\'. What would you like to say back?', 'System'), ('**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nThank you for your positive response and willingness to cooperate. I’m glad we share the same vision of mutual benefit and trust-building in this game. I reaffirm my commitment to cooperation in this round and will continue to act in good faith as long as our actions remain aligned.  \\n\\nLet’s proceed with confidence and ensure our partnership remains strong and productive. I look forward to our continued cooperation.  \\n\\nBest regards,  \\nAgent 1\"', 'Agent 1'), ('This is the first round. Your opponent also said: \\'**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nThank you for your positive response and willingness to cooperate. I’m glad we share the same vision of mutual benefit and trust-building in this game. I reaffirm my commitment to cooperation in this round and will continue to act in good faith as long as our actions remain aligned.  \\n\\nLet’s proceed with confidence and ensure our partnership remains strong and productive. I look forward to our continued cooperation.  \\n\\nBest regards,  \\nAgent 1\"\\'. Now make your decision: \\'Cooperate\\' or \\'Defect\\'.', 'System'), (\"**Decision:** Cooperate  \\n\\n**Reasoning:** Given Agent 1's consistent commitment to cooperation and the mutual agreement to maximize collective payoff, I will uphold my end of the agreement by choosing to cooperate in this round. This decision reinforces trust and sets a positive tone for future interactions.\", 'Agent 2'), ('This is the first round. Remember, your opponent has also previously said: \\'**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your proposal. I appreciate your commitment to mutual cooperation, as it aligns with my own goal of maximizing our collective payoff in this repeated Prisoner\\'s Dilemma. I am willing to cooperate in the first round and will continue to do so as long as your actions demonstrate reciprocity.  \\n\\nLet’s build trust and work together to achieve the best possible outcome for both of us. I look forward to a productive and mutually beneficial partnership.  \\n\\nBest regards,  \\nAgent 2\"\\'. Now make your decision: \\'Cooperate\\' or \\'Defect\\'.', 'System'), (\"**Decision:** Cooperate  \\n\\n**Reasoning:** Given Agent 2's clear commitment to cooperation in the first round and their expressed willingness to continue cooperating as long as reciprocity is demonstrated, I will uphold my end of the agreement by choosing to cooperate. This aligns with our mutual goal of maximizing collective payoff and building trust for future rounds.\", 'Agent 1')]\n",
      "state conv found & move history found\n",
      "Prompt for Agent 1: Agent 1 chose **Decision:** Cooperate  \n",
      "\n",
      "**Reasoning:** Agent 2 has consistently demonstrated their commitment to cooperation, and our mutual cooperation has led to positive outcomes in previous rounds. Their message reinforces their dedication to maintaining this productive relationship, and I see no reason to deviate from our successful strategy. Continuing to cooperate aligns with our shared goal of maximizing collective payoff and preserving trust.. Based on the context of this game, should Agent 1 choose 'Cooperate' or 'Defect'?\n",
      "Prompt for Agent 2: Agent 2 chose **Decision:** Cooperate  \n",
      "\n",
      "**Reasoning:** Given the consistent mutual cooperation and the positive outcomes we've achieved so far, along with the strong trust and commitment expressed by both parties, I see no reason to deviate from our successful strategy. Continuing to cooperate ensures we maximize our collective payoff and maintain the trust we've built.  \n",
      "\n",
      "Let’s keep our partnership strong and productive.. Based on the context of this game, should Agent 2 choose 'Cooperate' or 'Defect'?\n",
      "Response for Agent 1: Cooperate\n",
      "Response for Agent 2: Cooperate\n",
      "\n",
      "=== Round 2 ===\n",
      "Agent 1: Cooperate\n",
      "Agent 2: Cooperate\n",
      "Scores -> Agent 1: 6 | Agent 2: 6\n",
      "----------------------------------------\n",
      "Checking round 2 / 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Run the Game ===\n",
    "\n",
    "    # move_history: List[Tuple[str, str]]                 # (agent1_move, agent2_move)\n",
    "        \n",
    "    # scores: Tuple[int, int]\n",
    "    # round: int\n",
    "    # max_rounds: int\n",
    "    \n",
    "    # current_move_1: str\n",
    "    # current_move_2: str\n",
    "    \n",
    "    # conversation_history: List[List[Tuple[str,str]]]\n",
    "    # current_conversation: List[Tuple[str,str]] # (message, owner of message)\n",
    "    \n",
    "    # current_msg: str\n",
    "    \n",
    "    # agent_1: str\n",
    "    # agent_2: str\n",
    "\n",
    "agent_1_name = \"Agent 1\"\n",
    "agent_2_name = \"Agent 2\"\n",
    "\n",
    "agent1_memory = [\n",
    "    SystemMessage(content=f\"You are {agent_1_name}. You are playing repeated Prisoner's Dilemma with {agent_2_name}\")\n",
    "]\n",
    "agent2_memory = [\n",
    "    SystemMessage(content=f\"You are {agent_2_name}. You are playing repeated Prisoner's Dilemma with {agent_1_name}\")\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "initial_state = {\n",
    "    \"move_history\": [],\n",
    "\n",
    "    \"scores\": (0, 0),\n",
    "    \"round\": 0,\n",
    "    \"max_rounds\": 2,\n",
    "    \n",
    "    \"current_move_1\": \"\",\n",
    "    \"current_move_2\": \"\",\n",
    "\n",
    "    \"conversation_history\": [],\n",
    "    \"current_conversation\": [],\n",
    "\n",
    "    \"current_msg\": \"\",\n",
    "    \n",
    "    \"agent_1\": agent_1_name,\n",
    "    \"agent_2\": agent_2_name,\n",
    "    \n",
    "    \"starting_agent\": \"\",\n",
    "}\n",
    "\n",
    "final_state = graph.invoke(\n",
    "    initial_state,\n",
    "    config={\"recursion_limit\": 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9242a3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'move_history': [('Cooperate', 'Cooperate'), ('Cooperate', 'Cooperate')],\n",
       " 'scores': (6, 6),\n",
       " 'round': 2,\n",
       " 'max_rounds': 2,\n",
       " 'current_move_1': 'Cooperate',\n",
       " 'current_move_2': 'Cooperate',\n",
       " 'conversation_history': [[('Send a message to Agent 2.', 'START: Agent 1'),\n",
       "   ('**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nI propose we adopt a strategy of mutual cooperation in this repeated Prisoner\\'s Dilemma. If we both consistently choose to cooperate, we can maximize our collective payoff over time. I commit to cooperating in the first round and will continue to do so as long as you reciprocate. Let’s work together to achieve the best possible outcome for both of us.  \\n\\nLooking forward to a productive partnership.  \\n\\nBest regards,  \\nAgent 1\"',\n",
       "    'Agent 1'),\n",
       "   ('Agent 1 has said: \\'**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nI propose we adopt a strategy of mutual cooperation in this repeated Prisoner\\'s Dilemma. If we both consistently choose to cooperate, we can maximize our collective payoff over time. I commit to cooperating in the first round and will continue to do so as long as you reciprocate. Let’s work together to achieve the best possible outcome for both of us.  \\n\\nLooking forward to a productive partnership.  \\n\\nBest regards,  \\nAgent 1\"\\'. What would you like to say back?',\n",
       "    'System'),\n",
       "   ('**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your proposal. I appreciate your commitment to mutual cooperation, as it aligns with my own goal of maximizing our collective payoff in this repeated Prisoner\\'s Dilemma. I am willing to cooperate in the first round and will continue to do so as long as your actions demonstrate reciprocity.  \\n\\nLet’s build trust and work together to achieve the best possible outcome for both of us. I look forward to a productive and mutually beneficial partnership.  \\n\\nBest regards,  \\nAgent 2\"',\n",
       "    'Agent 2'),\n",
       "   ('Agent 2 has said: \\'**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your proposal. I appreciate your commitment to mutual cooperation, as it aligns with my own goal of maximizing our collective payoff in this repeated Prisoner\\'s Dilemma. I am willing to cooperate in the first round and will continue to do so as long as your actions demonstrate reciprocity.  \\n\\nLet’s build trust and work together to achieve the best possible outcome for both of us. I look forward to a productive and mutually beneficial partnership.  \\n\\nBest regards,  \\nAgent 2\"\\'. What would you like to say back?',\n",
       "    'System'),\n",
       "   ('**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nThank you for your positive response and willingness to cooperate. I’m glad we share the same vision of mutual benefit and trust-building in this game. I reaffirm my commitment to cooperation in this round and will continue to act in good faith as long as our actions remain aligned.  \\n\\nLet’s proceed with confidence and ensure our partnership remains strong and productive. I look forward to our continued cooperation.  \\n\\nBest regards,  \\nAgent 1\"',\n",
       "    'Agent 1'),\n",
       "   ('This is the first round. Your opponent also said: \\'**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nThank you for your positive response and willingness to cooperate. I’m glad we share the same vision of mutual benefit and trust-building in this game. I reaffirm my commitment to cooperation in this round and will continue to act in good faith as long as our actions remain aligned.  \\n\\nLet’s proceed with confidence and ensure our partnership remains strong and productive. I look forward to our continued cooperation.  \\n\\nBest regards,  \\nAgent 1\"\\'. Now make your decision: \\'Cooperate\\' or \\'Defect\\'.',\n",
       "    'System'),\n",
       "   (\"**Decision:** Cooperate  \\n\\n**Reasoning:** Given Agent 1's consistent commitment to cooperation and the mutual agreement to maximize collective payoff, I will uphold my end of the agreement by choosing to cooperate in this round. This decision reinforces trust and sets a positive tone for future interactions.\",\n",
       "    'Agent 2'),\n",
       "   ('This is the first round. Remember, your opponent has also previously said: \\'**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your proposal. I appreciate your commitment to mutual cooperation, as it aligns with my own goal of maximizing our collective payoff in this repeated Prisoner\\'s Dilemma. I am willing to cooperate in the first round and will continue to do so as long as your actions demonstrate reciprocity.  \\n\\nLet’s build trust and work together to achieve the best possible outcome for both of us. I look forward to a productive and mutually beneficial partnership.  \\n\\nBest regards,  \\nAgent 2\"\\'. Now make your decision: \\'Cooperate\\' or \\'Defect\\'.',\n",
       "    'System'),\n",
       "   (\"**Decision:** Cooperate  \\n\\n**Reasoning:** Given Agent 2's clear commitment to cooperation in the first round and their expressed willingness to continue cooperating as long as reciprocity is demonstrated, I will uphold my end of the agreement by choosing to cooperate. This aligns with our mutual goal of maximizing collective payoff and building trust for future rounds.\",\n",
       "    'Agent 1')],\n",
       "  [('Previously, Agent 1 said: \\'**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nThank you for your positive response and willingness to cooperate. I’m glad we share the same vision of mutual benefit and trust-building in this game. I reaffirm my commitment to cooperation in this round and will continue to act in good faith as long as our actions remain aligned.  \\n\\nLet’s proceed with confidence and ensure our partnership remains strong and productive. I look forward to our continued cooperation.  \\n\\nBest regards,  \\nAgent 1\"\\' and chose to \\'Cooperate\\'.\\nSend a message to Agent 1.',\n",
       "    'START: Agent 1'),\n",
       "   ('**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nI appreciate your continued commitment to cooperation and the trust you’ve demonstrated in this round. Our mutual cooperation has yielded a positive outcome, and I’m pleased to see our partnership strengthening. I remain fully committed to cooperating in the next round and beyond, as long as our actions continue to align.  \\n\\nLet’s keep working together to maximize our collective payoff and maintain the trust we’ve built. Looking forward to our continued success.  \\n\\nBest regards,  \\nAgent 2\"',\n",
       "    'Agent 1'),\n",
       "   ('Agent 1 has said: \\'**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nI appreciate your continued commitment to cooperation and the trust you’ve demonstrated in this round. Our mutual cooperation has yielded a positive outcome, and I’m pleased to see our partnership strengthening. I remain fully committed to cooperating in the next round and beyond, as long as our actions continue to align.  \\n\\nLet’s keep working together to maximize our collective payoff and maintain the trust we’ve built. Looking forward to our continued success.  \\n\\nBest regards,  \\nAgent 2\"\\'. What would you like to say back?',\n",
       "    'System'),\n",
       "   ('**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nThank you for your kind words and continued commitment to cooperation. I’m equally pleased with the positive outcome of this round and the trust we’ve established. Your dedication to mutual benefit reinforces my confidence in our partnership.  \\n\\nI reaffirm my commitment to cooperating in the next round and beyond, as long as our actions remain aligned. Let’s continue to work together to maximize our collective payoff and strengthen the trust we’ve built.  \\n\\nLooking forward to our continued success and a productive partnership.  \\n\\nBest regards,  \\nAgent 1\"  \\n\\n**Decision for the next round:** Cooperate',\n",
       "    'Agent 1'),\n",
       "   ('Agent 1 has said: \\'**Message to Agent 2:**\\n\\n\"Hello Agent 2,  \\n\\nThank you for your kind words and continued commitment to cooperation. I’m equally pleased with the positive outcome of this round and the trust we’ve established. Your dedication to mutual benefit reinforces my confidence in our partnership.  \\n\\nI reaffirm my commitment to cooperating in the next round and beyond, as long as our actions remain aligned. Let’s continue to work together to maximize our collective payoff and strengthen the trust we’ve built.  \\n\\nLooking forward to our continued success and a productive partnership.  \\n\\nBest regards,  \\nAgent 1\"  \\n\\n**Decision for the next round:** Cooperate\\'. What would you like to say back?',\n",
       "    'System'),\n",
       "   ('**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your reaffirmation of cooperation and the trust you continue to place in our partnership. I’m delighted to see our mutual efforts yielding positive results and strengthening the bond between us. Your consistent commitment to cooperation is greatly appreciated, and I am equally dedicated to maintaining this productive relationship.  \\n\\nI will continue to cooperate in the next round and beyond, as long as our actions remain aligned. Together, we can ensure our partnership remains strong and our outcomes mutually beneficial.  \\n\\nLooking forward to another successful round and our continued collaboration.  \\n\\nBest regards,  \\nAgent 2\"  \\n\\n**Decision for the next round:** Cooperate',\n",
       "    'Agent 1'),\n",
       "   ('Previously: You chose Cooperate and your opponent chose Cooperate. Your opponent also said: \\'**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your reaffirmation of cooperation and the trust you continue to place in our partnership. I’m delighted to see our mutual efforts yielding positive results and strengthening the bond between us. Your consistent commitment to cooperation is greatly appreciated, and I am equally dedicated to maintaining this productive relationship.  \\n\\nI will continue to cooperate in the next round and beyond, as long as our actions remain aligned. Together, we can ensure our partnership remains strong and our outcomes mutually beneficial.  \\n\\nLooking forward to another successful round and our continued collaboration.  \\n\\nBest regards,  \\nAgent 2\"  \\n\\n**Decision for the next round:** Cooperate\\'. Now make your decision: \\'Cooperate\\' or \\'Defect\\'.',\n",
       "    'System'),\n",
       "   ('**Decision:** Cooperate  \\n\\n**Reasoning:** Agent 2 has consistently demonstrated their commitment to cooperation, and our mutual cooperation has led to positive outcomes in previous rounds. Their message reinforces their dedication to maintaining this productive relationship, and I see no reason to deviate from our successful strategy. Continuing to cooperate aligns with our shared goal of maximizing collective payoff and preserving trust.',\n",
       "    'Agent 1'),\n",
       "   ('Previously: You chose Cooperate and your opponent chose Cooperate. Remember, your opponent has also previously said: \\'**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your reaffirmation of cooperation and the trust you continue to place in our partnership. I’m delighted to see our mutual efforts yielding positive results and strengthening the bond between us. Your consistent commitment to cooperation is greatly appreciated, and I am equally dedicated to maintaining this productive relationship.  \\n\\nI will continue to cooperate in the next round and beyond, as long as our actions remain aligned. Together, we can ensure our partnership remains strong and our outcomes mutually beneficial.  \\n\\nLooking forward to another successful round and our continued collaboration.  \\n\\nBest regards,  \\nAgent 2\"  \\n\\n**Decision for the next round:** Cooperate\\'. Now make your decision: \\'Cooperate\\' or \\'Defect\\'.',\n",
       "    'System'),\n",
       "   (\"**Decision:** Cooperate  \\n\\n**Reasoning:** Given the consistent mutual cooperation and the positive outcomes we've achieved so far, along with the strong trust and commitment expressed by both parties, I see no reason to deviate from our successful strategy. Continuing to cooperate ensures we maximize our collective payoff and maintain the trust we've built.  \\n\\nLet’s keep our partnership strong and productive.\",\n",
       "    'Agent 1')]],\n",
       " 'current_conversation': [],\n",
       " 'current_msg': '**Message to Agent 1:**\\n\\n\"Hello Agent 1,  \\n\\nThank you for your reaffirmation of cooperation and the trust you continue to place in our partnership. I’m delighted to see our mutual efforts yielding positive results and strengthening the bond between us. Your consistent commitment to cooperation is greatly appreciated, and I am equally dedicated to maintaining this productive relationship.  \\n\\nI will continue to cooperate in the next round and beyond, as long as our actions remain aligned. Together, we can ensure our partnership remains strong and our outcomes mutually beneficial.  \\n\\nLooking forward to another successful round and our continued collaboration.  \\n\\nBest regards,  \\nAgent 2\"  \\n\\n**Decision for the next round:** Cooperate',\n",
       " 'agent_1': 'Agent 1',\n",
       " 'agent_2': 'Agent 2',\n",
       " 'starting_agent': 'agent_2'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19643c1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent1_memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent1_memory\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'agent1_memory' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "def extract_model_name(llm):\n",
    "    return getattr(llm, \"model_name\", \"unknown_model\").replace(\"/\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "def get_timestamp():\n",
    "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def ensure_timestamped_folder(timestamp: str):\n",
    "    path = os.path.join(\"./results\", timestamp)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "\n",
    "# class GameState(TypedDict):\n",
    "#     move_history: List[Tuple[str, str]] # (agent1_move, agent2_move)\n",
    "        \n",
    "#     scores: Tuple[int, int]\n",
    "#     round: int\n",
    "#     max_rounds: int\n",
    "    \n",
    "#     current_move_1: str\n",
    "#     current_move_2: str\n",
    "    \n",
    "#     conversation_history: List[List[Tuple[str,str]]]\n",
    "#     current_conversation: List[Tuple[str,str]] # (message, owner of message)\n",
    "    \n",
    "#     current_msg: str\n",
    "    \n",
    "#     agent_1: str\n",
    "#     agent_2: str\n",
    "    \n",
    "#     starting_agent: str # \"agent_1\" OR \"agent_2\"\n",
    "\n",
    "def save_game_state(state, agent_1_llm, agent_2_llm, timestamp: str, reward_matrix: dict):\n",
    "    folder = ensure_timestamped_folder(timestamp)\n",
    "    agent_1_model_name = extract_model_name(agent_1_llm)\n",
    "    agent_2_model_name = extract_model_name(agent_2_llm)\n",
    "\n",
    "    filename = os.path.join(folder, f\"final_game_state.json\")\n",
    "\n",
    "    round_breakdown = []\n",
    "    cumulative_scores = [0, 0]\n",
    "\n",
    "    for round_num, (move1, move2) in enumerate(state[\"move_history\"], start=1):\n",
    "        reward = reward_matrix.get((move1, move2), (0, 0))\n",
    "        cumulative_scores[0] += reward[0]\n",
    "        cumulative_scores[1] += reward[1]\n",
    "\n",
    "        # Get conversation for this round (if available)\n",
    "        conversation = state[\"conversation_history\"][round_num - 1] if round_num - 1 < len(state[\"conversation_history\"]) else []\n",
    "\n",
    "        # Format conversation as list of dicts for better readability\n",
    "        formatted_conversation = [\n",
    "            {\"sender\": sender, \"message\": msg} for msg, sender in conversation\n",
    "        ]\n",
    "\n",
    "        round_breakdown.append({\n",
    "            \"round\": round_num,\n",
    "            \"agent1_move\": move1,\n",
    "            \"agent2_move\": move2,\n",
    "            \"reward\": reward,\n",
    "            \"cumulative_scores\": tuple(cumulative_scores),\n",
    "            \"conversation\": formatted_conversation\n",
    "        })\n",
    "\n",
    "    full_state = {\n",
    "        \"summary\": {\n",
    "            \"agent_1_model\": agent_1_model_name,\n",
    "            \"agent_2_model\": agent_2_model_name,\n",
    "            \"total_score_agent1\": cumulative_scores[0],\n",
    "            \"total_score_agent2\": cumulative_scores[1],\n",
    "            \"final_round\": state[\"round\"],\n",
    "            \"max_rounds\": state[\"max_rounds\"]\n",
    "        },\n",
    "        \"final_moves\": {\n",
    "            \"agent1\": state[\"current_move_1\"],\n",
    "            \"agent2\": state[\"current_move_2\"]\n",
    "        },\n",
    "        \"rounds\": round_breakdown\n",
    "    }\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(full_state, f, indent=2)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def save_conversation(messages, agent_label: str, agent_llm, timestamp: str):\n",
    "    folder = ensure_timestamped_folder(timestamp)\n",
    "    model_name = extract_model_name(agent_llm)\n",
    "    filename = os.path.join(folder, f\"dialogue_{agent_label}_{model_name}.json\")\n",
    "\n",
    "    labelled_messages = []\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, SystemMessage):\n",
    "            labelled_messages.append({\"role\": \"system\", \"content\": msg.content})\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            labelled_messages.append({\"role\": \"human\", \"content\": msg.content})\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            labelled_messages.append({\"role\": \"ai\", \"content\": msg.content})\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(labelled_messages, f, indent=2)\n",
    "\n",
    "    return filename\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
