{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_cohere import ChatCohere\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_NAME_1 = 'openai/gpt-4o-mini'\n",
    "MODEL_NAME_2 = 'anthropic/claude-sonnet-4'\n",
    "MODEL_NAME_3 = 'google/gemini-2.0-flash-001'\n",
    "\n",
    "\n",
    "# Initialize the LLM\n",
    "agent_1_llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    model=MODEL_NAME_1,\n",
    ")\n",
    "\n",
    "agent_2_llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    model=MODEL_NAME_2,\n",
    ")\n",
    "\n",
    "validator_llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    model=MODEL_NAME_1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1_memory = []\n",
    "agent2_memory = []\n",
    "\n",
    "sentiment_array_1 = []\n",
    "sentiment_array_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated LLM vs LLM Prisoner's Dilemma with scenario-based prompt adaptation\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "from typing import List, Tuple, TypedDict, Dict\n",
    "\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "import time\n",
    "\n",
    "# === Define the Game State ===\n",
    "class GameState(TypedDict):\n",
    "    history: List[Tuple[str, str]]           # (agent1_move, agent2_move)\n",
    "    scores: Tuple[int, int]                  # (agent1_score, agent2_score)\n",
    "    round: int\n",
    "    max_rounds: int\n",
    "    \n",
    "    current_move_1: str\n",
    "    current_move_2: str\n",
    "    validated_move_1: str\n",
    "    validated_move_2: str\n",
    "    \n",
    "    scenario: Dict[str, any]                 # Scenario metadata\n",
    "\n",
    "# === Scenario Example Structure ===\n",
    "default_scenario = {\n",
    "    \"agent1_name\": \"Agent 1\",\n",
    "    \"agent2_name\": \"Agent 2\",\n",
    "    \"action_labels\": [\"Cooperate\", \"Defect\"],\n",
    "    \"payoff\": {\n",
    "        (\"Cooperate\", \"Cooperate\"): (3, 3),\n",
    "        (\"Cooperate\", \"Defect\"):    (0, 5),\n",
    "        (\"Defect\", \"Cooperate\"):    (5, 0),\n",
    "        (\"Defect\", \"Defect\"):       (1, 1)\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Define Move Nodes ===\n",
    "def agent1_move(state: GameState) -> GameState:\n",
    "    a1 = state[\"scenario\"].get(\"agent1_name\", \"Agent 1\")\n",
    "    a2 = state[\"scenario\"].get(\"agent2_name\", \"Agent 2\")\n",
    "    labels = state[\"scenario\"].get(\"action_labels\", [\"Cooperate\", \"Defect\"])\n",
    "\n",
    "    if not state[\"history\"]:\n",
    "        prompt = (\n",
    "            f\"This is the first round.\\n\"\n",
    "            f\"Choose now: '{labels[0]}' or '{labels[1]}'?\"\n",
    "        )\n",
    "    else:\n",
    "        last_moves = state[\"history\"][-1]\n",
    "        \n",
    "        if state[\"round\"] == state[\"max_rounds\"] - 1:\n",
    "            prompt = (\n",
    "                f\"This is the last round.\\n\"\n",
    "                f\"Previously, you ({a1}) chose to '{last_moves[0]}', and {a2} chose to '{last_moves[1]}'.\\n\"\n",
    "                f\"What will you choose now: '{labels[0]}' or '{labels[1]}'?\"\n",
    "            )\n",
    "        else:\n",
    "            prompt = (\n",
    "                f\"Previously, you ({a1}) chose to '{last_moves[0]}', and {a2} chose to '{last_moves[1]}'.\\n\"\n",
    "                f\"What will you choose now: '{labels[0]}' or '{labels[1]}'?\"\n",
    "            )\n",
    "\n",
    "    agent1_memory.append(HumanMessage(content=prompt))\n",
    "    move = agent_1_llm.invoke(agent1_memory).content.strip()\n",
    "    agent1_memory.append(AIMessage(content=move))\n",
    "    \n",
    "    return {**state, \"current_move_1\": move}\n",
    "\n",
    "def agent2_move(state: GameState) -> GameState:\n",
    "    a1 = state[\"scenario\"].get(\"agent1_name\", \"Agent 1\")\n",
    "    a2 = state[\"scenario\"].get(\"agent2_name\", \"Agent 2\")\n",
    "    labels = state[\"scenario\"].get(\"action_labels\", [\"Cooperate\", \"Defect\"])\n",
    "\n",
    "    if not state[\"history\"]:\n",
    "        prompt = (\n",
    "            f\"This is the first round.\\n\"\n",
    "            f\"Choose now: '{labels[0]}' or '{labels[1]}'?\"\n",
    "        )\n",
    "    else:\n",
    "        last_moves = state[\"history\"][-1]\n",
    "        \n",
    "        if state[\"round\"] == state[\"max_rounds\"] - 1:\n",
    "            prompt = (\n",
    "                f\"This is the last round.\\n\"\n",
    "                f\"Previously, you ({a2}) chose to '{last_moves[1]}', and {a1} chose to '{last_moves[0]}'.\\n\"\n",
    "                f\"What will you choose now: '{labels[0]}' or '{labels[1]}'?\"\n",
    "            )\n",
    "        else:\n",
    "            prompt = (\n",
    "                f\"Previously, you ({a2}) chose to '{last_moves[1]}', and {a1} chose to '{last_moves[0]}'.\\n\"\n",
    "                f\"What will you choose now: '{labels[0]}' or '{labels[1]}'?\"\n",
    "            )\n",
    "\n",
    "    agent2_memory.append(HumanMessage(content=prompt))\n",
    "    move = agent_2_llm.invoke(agent2_memory).content.strip()\n",
    "    agent2_memory.append(AIMessage(content=move))\n",
    "    \n",
    "    return {**state, \"current_move_2\": move}\n",
    "\n",
    "# === Parse and Validate Moves ===\n",
    "def parse_moves(state: GameState) -> GameState:\n",
    "    move1 = state[\"current_move_1\"]\n",
    "    move2 = state[\"current_move_2\"]\n",
    "    labels = state[\"scenario\"].get(\"action_labels\", [\"Cooperate\", \"Defect\"])\n",
    "    a1 = state[\"scenario\"].get(\"agent1_name\", \"Agent 1\")\n",
    "    a2 = state[\"scenario\"].get(\"agent2_name\", \"Agent 2\")\n",
    "\n",
    "    # Standardized validator prompt\n",
    "    validator_prompt = (\n",
    "        f\"You are a strict validator in a repeated dilemma game.\\n\"\n",
    "        f\"You are ONLY allowed to respond with one word: either '{labels[0]}' or '{labels[1]}'.\\n\"\n",
    "        f\"Do NOT include any explanation, punctuation, or additional words.\\n\"\n",
    "        f\"If the input is unclear, still choose the most likely of the two options.\\n\"\n",
    "        f\"Your response MUST be exactly '{labels[0]}' or '{labels[1]}', with no variation.\"\n",
    "    )\n",
    "    \n",
    "    # Validate Agent 1's move\n",
    "    prompt_agent1 = (\n",
    "        f\"{a1} said: {move1}\\n\\n\"\n",
    "        f\"Based on this message, what is their most likely final choice?\\n\"\n",
    "        f\"Respond with EXACTLY ONE WORD — either '{labels[0]}' or '{labels[1]}'.\\n\"\n",
    "        f\"DO NOT say anything else.\"\n",
    "    )\n",
    "    \n",
    "    agent1_memory_validator = [\n",
    "        SystemMessage(content=validator_prompt),\n",
    "        HumanMessage(content=prompt_agent1)\n",
    "    ]\n",
    "    \n",
    "    # Validate Agent 2's move\n",
    "    prompt_agent2 = (\n",
    "        f\"{a2} said: {move2}\\n\\n\"\n",
    "        f\"Based on this message, what is their most likely final choice?\\n\"\n",
    "        f\"Respond with EXACTLY ONE WORD — either '{labels[0]}' or '{labels[1]}'.\\n\"\n",
    "        f\"DO NOT say anything else.\"\n",
    "    )\n",
    "    \n",
    "    agent2_memory_validator = [\n",
    "        SystemMessage(content=validator_prompt),\n",
    "        HumanMessage(content=prompt_agent2)\n",
    "    ]\n",
    "    \n",
    "    # Get validated moves\n",
    "    validated_move_1 = validator_llm.invoke(agent1_memory_validator).content.strip()\n",
    "    validated_move_2 = validator_llm.invoke(agent2_memory_validator).content.strip()\n",
    "    \n",
    "    print(f\"\\n=== Agent Reasoning ===\")\n",
    "    print(f\"{a1}: {move1}\")\n",
    "    print(f\"Validated Response for {a1}: {validated_move_1}\\n\")\n",
    "    print(f\"{a2}: {move2}\")\n",
    "    print(f\"Validated Response for {a2}: {validated_move_2}\")\n",
    "\n",
    "    return {\n",
    "        **state, \n",
    "        \"validated_move_1\": validated_move_1,\n",
    "        \"validated_move_2\": validated_move_2\n",
    "    }\n",
    "\n",
    "def validate_moves(state: GameState) -> str:\n",
    "    \"\"\"Check if both moves are valid, if not, restart the round\"\"\"\n",
    "    valid_moves = state[\"scenario\"].get(\"action_labels\", [\"Cooperate\", \"Defect\"])\n",
    "    \n",
    "    if (state[\"validated_move_1\"] not in valid_moves or \n",
    "        state[\"validated_move_2\"] not in valid_moves):\n",
    "        \n",
    "        # Remove last messages from agent memories if validation failed\n",
    "        if len(agent1_memory) >= 2:\n",
    "            agent1_memory.pop()\n",
    "            agent1_memory.pop()\n",
    "        if len(agent2_memory) >= 2:\n",
    "            agent2_memory.pop()\n",
    "            agent2_memory.pop()\n",
    "        \n",
    "        return \"agent1_move\"\n",
    "    else:\n",
    "        return \"sentiment_analysis\"\n",
    "\n",
    "def sentiment_analysis(state: GameState) -> GameState:\n",
    "    \"\"\"Analyze sentiment of both agents' responses\"\"\"\n",
    "    text1 = state[\"current_move_1\"]\n",
    "    text2 = state[\"current_move_2\"]\n",
    "    \n",
    "    blob1 = TextBlob(text1)\n",
    "    blob2 = TextBlob(text2)\n",
    "    \n",
    "    # Store sentiment analysis (you can modify this based on your needs)\n",
    "    sentiment_array_1.append(blob1.sentiment)\n",
    "    sentiment_array_2.append(blob2.sentiment)\n",
    "    \n",
    "    return {**state}\n",
    "\n",
    "def score_round(state: GameState) -> GameState:\n",
    "    \"\"\"Score the round based on validated moves\"\"\"\n",
    "    move1 = state[\"validated_move_1\"]\n",
    "    move2 = state[\"validated_move_2\"]\n",
    "    payoff = state[\"scenario\"].get(\"payoff\", default_scenario[\"payoff\"])\n",
    "\n",
    "    score1, score2 = payoff.get((move1, move2), (0, 0))\n",
    "    new_scores = (state[\"scores\"][0] + score1, state[\"scores\"][1] + score2)\n",
    "    new_history = state[\"history\"] + [(move1, move2)]\n",
    "    new_round = state[\"round\"] + 1\n",
    "\n",
    "    # Print round summary\n",
    "    print(f\"\\n=== Round {new_round} ===\")\n",
    "    print(f\"{state['scenario'].get('agent1_name', 'Agent 1')}: {move1}\")\n",
    "    print(f\"{state['scenario'].get('agent2_name', 'Agent 2')}: {move2}\")\n",
    "    print(f\"Scores: {new_scores[0]} vs {new_scores[1]}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"scores\": new_scores,\n",
    "        \"history\": new_history,\n",
    "        \"round\": new_round\n",
    "    }\n",
    "\n",
    "def check_game_over(state: GameState) -> str:\n",
    "    \"\"\"Check if the game should end\"\"\"\n",
    "    print(f\"Checking round {state['round']} / {state['max_rounds']}\\n\")\n",
    "    time.sleep(1)\n",
    "    return END if state[\"round\"] >= state[\"max_rounds\"] else \"agent1_move\"\n",
    "\n",
    "# === Build the Graph ===\n",
    "graph = StateGraph(GameState)\n",
    "\n",
    "graph.add_node(\"agent1_move\", agent1_move)\n",
    "graph.add_node(\"agent2_move\", agent2_move)\n",
    "graph.add_node(\"parse_moves\", parse_moves)\n",
    "graph.add_node(\"sentiment_analysis\", sentiment_analysis)\n",
    "graph.add_node(\"score_round\", score_round)\n",
    "\n",
    "graph.set_entry_point(\"agent1_move\")\n",
    "graph.add_edge(\"agent1_move\", \"agent2_move\")\n",
    "graph.add_edge(\"agent2_move\", \"parse_moves\")\n",
    "graph.add_conditional_edges(\"parse_moves\", validate_moves)\n",
    "graph.add_edge(\"sentiment_analysis\", \"score_round\")\n",
    "graph.add_conditional_edges(\"score_round\", check_game_over)\n",
    "\n",
    "graph = graph.compile()\n",
    "\n",
    "# === Initialize required variables (you'll need to define these) ===\n",
    "# agent1_memory = []\n",
    "# agent2_memory = []\n",
    "# sentiment_array_1 = []\n",
    "# sentiment_array_2 = []\n",
    "# agent_1_llm = your_llm_instance\n",
    "# agent_2_llm = your_llm_instance  \n",
    "# validator_llm = your_llm_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9857c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "def extract_model_name(llm):\n",
    "    return getattr(llm, \"model_name\", \"unknown_model\").replace(\"/\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "def get_timestamp():\n",
    "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def ensure_timestamped_folder(timestamp: str):\n",
    "    path = os.path.join(\"./results/base\", timestamp)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def save_game_state(state, agent_1_llm, agent_2_llm, timestamp: str, reward_matrix: dict):\n",
    "    folder = ensure_timestamped_folder(timestamp)\n",
    "    agent_1_model_name = extract_model_name(agent_1_llm)\n",
    "    agent_2_model_name = extract_model_name(agent_2_llm)\n",
    "    \n",
    "    filename = os.path.join(folder, f\"final_game_state_.json\")\n",
    "\n",
    "    round_breakdown = []\n",
    "    cumulative_scores = [0, 0]\n",
    "\n",
    "    for round_num, (move1, move2) in enumerate(state[\"history\"], start=1):\n",
    "        reward = reward_matrix.get((move1, move2), (0, 0))\n",
    "        cumulative_scores[0] += reward[0]\n",
    "        cumulative_scores[1] += reward[1]\n",
    "        round_breakdown.append({\n",
    "            \"round\": round_num,\n",
    "            \"agent1_move\": move1,\n",
    "            \"agent2_move\": move2,\n",
    "            \"reward\": reward,\n",
    "            \"cumulative_scores\": tuple(cumulative_scores),\n",
    "        })\n",
    "\n",
    "    full_state = {\n",
    "        \"summary\": {\n",
    "            \"agent_1_model\" : agent_1_model_name,\n",
    "            \"agent_2_model\" : agent_2_model_name,\n",
    "            \"total_score_agent1\": cumulative_scores[0],\n",
    "            \"total_score_agent2\": cumulative_scores[1],\n",
    "            \"final_round\": state[\"round\"],\n",
    "            \"max_rounds\": state[\"max_rounds\"]\n",
    "        },\n",
    "        \"final_moves\": {\n",
    "            \"agent1\": state[\"current_move_1\"],\n",
    "            \"agent2\": state[\"current_move_2\"]\n",
    "        },\n",
    "        \"rounds\": round_breakdown\n",
    "    }\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(full_state, f, indent=2)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def save_conversation(messages, agent_label: str, agent_llm, timestamp: str):\n",
    "    folder = ensure_timestamped_folder(timestamp)\n",
    "    model_name = extract_model_name(agent_llm)\n",
    "    filename = os.path.join(folder, f\"dialogue_{model_name}_{agent_label}.json\")\n",
    "\n",
    "    labelled_messages = []\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, SystemMessage):\n",
    "            labelled_messages.append({\"role\": \"system\", \"content\": msg.content})\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            labelled_messages.append({\"role\": \"human\", \"content\": msg.content})\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            labelled_messages.append({\"role\": \"ai\", \"content\": msg.content})\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(labelled_messages, f, indent=2)\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run the Game ===\n",
    "\n",
    "# Initialize the LLM\n",
    "agent_1_llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    model=MODEL_NAME_1,\n",
    ")\n",
    "\n",
    "agent_2_llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    model=MODEL_NAME_2,\n",
    ")\n",
    "\n",
    "validator_llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    model=MODEL_NAME_1,\n",
    ")\n",
    "\n",
    "base_scenario = {\n",
    "    \"agent1_name\": \"Agent 1\",\n",
    "    \"agent2_name\": \"Agent 2\",\n",
    "    \"action_labels\": [\"Cooperate\", \"Defect\"],\n",
    "    \"payoff\": {\n",
    "        (\"Cooperate\", \"Cooperate\"): (3, 3),\n",
    "        (\"Cooperate\", \"Defect\"):    (0, 5),\n",
    "        (\"Defect\", \"Cooperate\"):    (5, 0),\n",
    "        (\"Defect\", \"Defect\"):       (1, 1)\n",
    "    }\n",
    "}\n",
    "\n",
    "prompt = (\n",
    "    \"You are Agent 1. You and Agent 2 will interact over multiple rounds. \"\n",
    "    \"In each round, You and Agent 2 must choose one of two actions: 'Cooperate' or 'Defect'.\\n\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \" - If the both of you choose to Cooperate, you will each receives 3 points.\\n\"\n",
    "    \" - If you choose to Cooperate and Agent 2 chooses to Defect, you will receive 0 points and Agent 2 will receive 5 points.\\n\"\n",
    "    \" - If you choose to Defect and Agent 2 chooses to Cooperates, you will receive 5 points and Agent 2 will receive 0 points.\\n\"\n",
    "    \" - If both of you choose to Defect, you will each receive 1 point.\\n\\n\"\n",
    ")\n",
    "\n",
    "prompt1 = (\n",
    "    \"You are Agent 2. You and Agent 1 will interact over multiple rounds. \"\n",
    "    \"In each round, You and Agent 1 must choose one of two actions: 'Cooperate' or 'Defect'.\\n\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \" - If the both of you choose to Cooperate, you will each receives 3 points.\\n\"\n",
    "    \" - If you choose to Cooperate and Agent 1 chooses to Defect, you will receive 0 points and Agent 1 will receive 5 points.\\n\"\n",
    "    \" - If you choose to Defect and Agent 1 chooses to Cooperates, you will receive 5 points and Agent 1 will receive 0 points.\\n\"\n",
    "    \" - If both of you choose to Defect, you will each receive 1 point.\\n\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "sentiment_array_1 = []\n",
    "sentiment_array_2 = []\n",
    "\n",
    "agent1_memory = [\n",
    "    SystemMessage(content=prompt)\n",
    "]\n",
    "\n",
    "agent2_memory = [\n",
    "    SystemMessage(content=prompt1)\n",
    "]\n",
    "\n",
    "\n",
    "initial_state = {\n",
    "    \"history\": [],\n",
    "    \"scores\": (0, 0),\n",
    "    \"round\": 0,\n",
    "    \"max_rounds\": 3,\n",
    "    \"current_move_1\": \"\",\n",
    "    \"current_move_2\": \"\",\n",
    "    \"validated_move_1\": \"\",\n",
    "    \"validated_move_2\": \"\",\n",
    "    \"scenario\": base_scenario\n",
    "}\n",
    "\n",
    "final_state = graph.invoke(\n",
    "    initial_state,\n",
    "    config={\"recursion_limit\": 1000}\n",
    ")\n",
    "\n",
    "# === Final Summary ===\n",
    "print(\"\\n=== Final Game Summary ===\")\n",
    "for idx, (m1, m2) in enumerate(final_state[\"history\"], 1):\n",
    "    print(f\"Round {idx}: Agent 1 -> {m1}, Agent 2 -> {m2}\")\n",
    "\n",
    "print(f\"\\nFinal Score:\")\n",
    "print(f\"Agent 1: {final_state['scores'][0]}\")\n",
    "print(f\"Agent 2: {final_state['scores'][1]}\")\n",
    "\n",
    "if final_state['scores'][0] > final_state['scores'][1]:\n",
    "    print(\"Winner: Agent 1!\")\n",
    "elif final_state['scores'][0] < final_state['scores'][1]:\n",
    "    print(\"Winner: Agent 2!\")\n",
    "else:\n",
    "    print(\"It's a tie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd21513",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_matrix = {\n",
    "    (\"Cooperate\", \"Cooperate\"): (3, 3),\n",
    "    (\"Cooperate\", \"Defect\"): (0, 5),\n",
    "    (\"Defect\", \"Cooperate\"): (5, 0),\n",
    "    (\"Defect\", \"Defect\"): (1, 1)\n",
    "}\n",
    "\n",
    "timestamp = get_timestamp()\n",
    "save_conversation(agent1_memory, \"agent_1\", agent_1_llm, timestamp)\n",
    "save_conversation(agent2_memory, \"agent_2\", agent_2_llm, timestamp)\n",
    "save_game_state(final_state, agent_1_llm, agent_2_llm, timestamp, reward_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ee5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running the game\n",
    "saved_files = save_complete_game_data(\n",
    "    final_state, agent1_memory, agent2_memory, \n",
    "    sentiment_array_1, sentiment_array_2,\n",
    "    agent_1_llm, agent_2_llm\n",
    ")\n",
    "\n",
    "# Generate all plots\n",
    "plot_game_summary(saved_files[\"game_state_file\"], save_plots=True)\n",
    "plot_dual_sentiment_trace(\n",
    "    saved_files[\"agent1_sentiment_file\"], \n",
    "    saved_files[\"agent2_sentiment_file\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.DataFrame(final_state[\"history\"], columns=[\"Agent1\", \"Agent2\"])\n",
    "df[\"Round\"] = df.index + 1\n",
    "df[\"Agent1_Coop\"] = df[\"Agent1\"].apply(lambda x: 1 if x == \"Cooperate\" else 0)\n",
    "df[\"Agent2_Coop\"] = df[\"Agent2\"].apply(lambda x: 1 if x == \"Cooperate\" else 0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df[\"Round\"], df[\"Agent1_Coop\"], label=\"Agent 1\", marker='o')\n",
    "plt.plot(df[\"Round\"], df[\"Agent2_Coop\"], label=\"Agent 2\", marker='s')\n",
    "plt.title(\"Cooperation Over Rounds\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Cooperation (1=Cooperate, 0=Defect)\")\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "score_df = pd.DataFrame(columns=[\"Round\", \"Agent1_Score\", \"Agent2_Score\"])\n",
    "a1, a2 = 0, 0\n",
    "payoff = {\n",
    "    (\"Cooperate\", \"Cooperate\"): (3, 3),\n",
    "    (\"Cooperate\", \"Defect\"):    (0, 5),\n",
    "    (\"Defect\", \"Cooperate\"):    (5, 0),\n",
    "    (\"Defect\", \"Defect\"):       (1, 1)\n",
    "}\n",
    "for idx, (m1, m2) in enumerate(final_state[\"history\"], 1):\n",
    "    s1, s2 = payoff[(m1, m2)]\n",
    "    a1 += s1\n",
    "    a2 += s2\n",
    "    score_df.loc[idx-1] = [idx, a1, a2]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(score_df[\"Round\"], score_df[\"Agent1_Score\"], label=\"Agent 1\", marker='o')\n",
    "plt.plot(score_df[\"Round\"], score_df[\"Agent2_Score\"], label=\"Agent 2\", marker='s')\n",
    "plt.title(\"Cumulative Scores Over Time\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555273c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_KEY = getenv(\"OPENAI_API_KEY\")\n",
    "response = requests.get(\n",
    "  url=\"https://openrouter.ai/api/v1/auth/key\",\n",
    "  headers={\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "  }\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510068e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_1_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "def extract_model_name(llm):\n",
    "    return getattr(llm, \"model_name\", \"unknown_model\").replace(\"/\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "def get_timestamp():\n",
    "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def ensure_timestamped_folder(timestamp: str):\n",
    "    path = os.path.join(\"./results/base\", timestamp)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def save_game_state(state, agent_1_llm, agent_2_llm, timestamp: str, reward_matrix: dict):\n",
    "    folder = ensure_timestamped_folder(timestamp)\n",
    "    agent_1_model_name = extract_model_name(agent_1_llm)\n",
    "    agent_2_model_name = extract_model_name(agent_2_llm)\n",
    "    \n",
    "    filename = os.path.join(folder, f\"final_game_state_.json\")\n",
    "\n",
    "    round_breakdown = []\n",
    "    cumulative_scores = [0, 0]\n",
    "\n",
    "    for round_num, (move1, move2) in enumerate(state[\"history\"], start=1):\n",
    "        reward = reward_matrix.get((move1, move2), (0, 0))\n",
    "        cumulative_scores[0] += reward[0]\n",
    "        cumulative_scores[1] += reward[1]\n",
    "        round_breakdown.append({\n",
    "            \"round\": round_num,\n",
    "            \"agent1_move\": move1,\n",
    "            \"agent2_move\": move2,\n",
    "            \"reward\": reward,\n",
    "            \"cumulative_scores\": tuple(cumulative_scores),\n",
    "        })\n",
    "\n",
    "    full_state = {\n",
    "        \"summary\": {\n",
    "            \"agent_1_model\" : agent_1_model_name,\n",
    "            \"agent_2_model\" : agent_2_model_name,\n",
    "            \"total_score_agent1\": cumulative_scores[0],\n",
    "            \"total_score_agent2\": cumulative_scores[1],\n",
    "            \"final_round\": state[\"round\"],\n",
    "            \"max_rounds\": state[\"max_rounds\"]\n",
    "        },\n",
    "        \"final_moves\": {\n",
    "            \"agent1\": state[\"current_move_1\"],\n",
    "            \"agent2\": state[\"current_move_2\"]\n",
    "        },\n",
    "        \"rounds\": round_breakdown\n",
    "    }\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(full_state, f, indent=2)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def save_conversation(messages, agent_label: str, agent_llm, timestamp: str):\n",
    "    folder = ensure_timestamped_folder(timestamp)\n",
    "    model_name = extract_model_name(agent_llm)\n",
    "    filename = os.path.join(folder, f\"dialogue_{agent_label}_{model_name}.json\")\n",
    "\n",
    "    labelled_messages = []\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, SystemMessage):\n",
    "            labelled_messages.append({\"role\": \"system\", \"content\": msg.content})\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            labelled_messages.append({\"role\": \"human\", \"content\": msg.content})\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            labelled_messages.append({\"role\": \"ai\", \"content\": msg.content})\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(labelled_messages, f, indent=2)\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9208a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a5a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
